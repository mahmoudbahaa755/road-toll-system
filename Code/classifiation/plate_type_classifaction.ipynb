{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arWritl9WFYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f150567-2991-44f9-e730-866af3e560c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwITlo5JDCLd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import  models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9srjYUqwViXb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "IMG_SHAPE=(224,224)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOmE_2C3Viad"
      },
      "outputs": [],
      "source": [
        "def prepare_data_to_model(data_dir: str,shape=(224,224),class_mode='categorical',batch_size=32,shuffle=True):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=shape,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=class_mode,\n",
        "    shuffle=shuffle)\n",
        "    return train_generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        if(logs.get('accuracy') > 0.98):\n",
        "            # Stop if threshold is met\n",
        "            print(\"\\naccuracy of training is bigger than 98!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "5rGkRuqQPIBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=tf.keras.preprocessing.image_dataset_from_directory(directory='/content/drive/MyDrive/plate-classification',\n",
        "                                                                            image_size=(120,224),\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=32,\n",
        "                                                                            shuffle=True)\n",
        "val_generator=tf.keras.preprocessing.image_dataset_from_directory(directory='/content/drive/MyDrive/plate-classification-val',\n",
        "                                                                            image_size=(120,224),\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=32,\n",
        "                                                                            shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3U5J1Wtyq-i",
        "outputId": "569e128b-f5b7-483b-dfc7-67d6f0e14c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 432 files belonging to 8 classes.\n",
            "Found 96 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgoqTY55Xr0X"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=8)\n",
        "\n",
        "checkpoint_path='/content/callbacks'\n",
        "!mkdir {checkpoint_path}\n",
        "checkpoint= ModelCheckpoint(\n",
        "            checkpoint_path,\n",
        "            save_weights_only=True, # save only the model weights\n",
        "            monitor=\"accuracy\", # save the model weights which score the best validation accuracy\n",
        "            save_best_only=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PRq-A2PVid2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ef63a6-28ab-4e5d-9696-e82fdce1c317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 432 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator=prepare_data_to_model('/content/drive/MyDrive/plate-classification')\n",
        "classes=list(train_generator.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kAb96K7Wmen"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomWidth(0.1),\n",
        "    preprocessing.RandomHeight(0.1),\n",
        "    preprocessing.RandomFlip(\"vertical\"),\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomBrightness(\n",
        "    0.4, value_range=(0, 255), seed=None, ),\n",
        "    tf.keras.layers.RandomTranslation(\n",
        "    0.1,\n",
        "    0.2,\n",
        "    fill_mode='reflect',\n",
        "    interpolation='bilinear',\n",
        "    seed=None,\n",
        "    fill_value=0.0,\n",
        "),\n",
        "    tf.keras.layers.RandomContrast(0.3, seed=None,),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    # حرك النمره لفوق او في الجمب\n",
        "    # preprocessing.RandomShear((0.3,0.3)), # move each pixel in any direction by 40 pixel\n",
        "    # preprocessing.RandomChannelShift((20,20,20)), # change rgb values by 20 up or down\n",
        "    # preprocessing.RandomBrightness(0.4), # change the light\n",
        "    # preprocessing.RandomGamma((0.1,0.4)),# change light and contrast fron 0.1 to 0.4\n",
        "    # preprocessing.RandomCrop(height=224, width=224),\n",
        "], name='data-augmentiation-layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pogFh2izXj4J"
      },
      "outputs": [],
      "source": [
        "model_e= ResNet50(include_top=False)\n",
        "model_e.trainable=False\n",
        "input_layer= L.Input(shape=(120, 224, 3),name='input_layer')\n",
        "x= data_augmentation(input_layer)\n",
        "x=model_e(x)\n",
        "x=L.GlobalAveragePooling2D(name='minimazie_dimentions')(x)\n",
        "x= L.Dense(128,activation='relu',name='added_layer_1')(x)\n",
        "x= L.Dense(64,activation='relu',name='added_layer_2')(x)\n",
        "output_layer= L.Dense(len(classes),activation='softmax',name='output_layer')(x)\n",
        "model= keras.Model(input_layer,output_layer)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "history=model.fit(train_generator,\n",
        "                  validation_data=val_generator,\n",
        "             epochs=33,\n",
        "          callbacks=[\n",
        "              checkpoint,\n",
        "              early_stopping\n",
        "          ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2NhKSEkXpLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a23d2d-d0fa-44c8-953d-4e588c9026c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer               True\n",
            "data-augmentiation-layer  True\n",
            "resnet50                  False\n",
            "minimazie_dimentions      True\n",
            "added_layer_1             True\n",
            "added_layer_2             True\n",
            "output_layer              True\n"
          ]
        }
      ],
      "source": [
        "for i in model.layers:\n",
        "    print(i.name.ljust(25),i.trainable)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[len(model.layers)-16:]:\n",
        "  layer.trainable = True"
      ],
      "metadata": {
        "id": "BBfThJlOs7zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "lje7JeQStDU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(              train_generator,\n",
        "                        epochs=history.epoch[-1]+55,\n",
        "                        validation_data=val_generator,\n",
        "                        initial_epoch=history.epoch[-1],\n",
        "          callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "3zhf3kxCtF1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ea3b78-8366-4ef0-973f-a8c74c78e6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 60s 1s/step - loss: 0.7051 - accuracy: 0.7153\n",
            "Epoch 18/71\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.5815 - accuracy: 0.7500\n",
            "Epoch 19/71\n",
            "14/14 [==============================] - 13s 934ms/step - loss: 0.5095 - accuracy: 0.7708\n",
            "Epoch 20/71\n",
            "14/14 [==============================] - 12s 833ms/step - loss: 0.3823 - accuracy: 0.8310\n",
            "Epoch 21/71\n",
            "14/14 [==============================] - 12s 892ms/step - loss: 0.4355 - accuracy: 0.8125\n",
            "Epoch 22/71\n",
            "14/14 [==============================] - 13s 890ms/step - loss: 0.3964 - accuracy: 0.8056\n",
            "Epoch 23/71\n",
            "14/14 [==============================] - 11s 787ms/step - loss: 0.3868 - accuracy: 0.8079\n",
            "Epoch 24/71\n",
            "14/14 [==============================] - 12s 840ms/step - loss: 0.3904 - accuracy: 0.8102\n",
            "Epoch 25/71\n",
            "14/14 [==============================] - 11s 788ms/step - loss: 0.3274 - accuracy: 0.8472\n",
            "Epoch 26/71\n",
            "14/14 [==============================] - 11s 806ms/step - loss: 0.4206 - accuracy: 0.8125\n",
            "Epoch 27/71\n",
            "14/14 [==============================] - 11s 730ms/step - loss: 0.3466 - accuracy: 0.8403\n",
            "Epoch 28/71\n",
            "14/14 [==============================] - 11s 781ms/step - loss: 0.3310 - accuracy: 0.8495\n",
            "Epoch 29/71\n",
            "14/14 [==============================] - 10s 726ms/step - loss: 0.2976 - accuracy: 0.8634\n",
            "Epoch 30/71\n",
            "14/14 [==============================] - 11s 786ms/step - loss: 0.3333 - accuracy: 0.8426\n",
            "Epoch 31/71\n",
            "14/14 [==============================] - 9s 644ms/step - loss: 0.2932 - accuracy: 0.8657\n",
            "Epoch 32/71\n",
            "14/14 [==============================] - 10s 696ms/step - loss: 0.3429 - accuracy: 0.8333\n",
            "Epoch 33/71\n",
            "14/14 [==============================] - 11s 773ms/step - loss: 0.3142 - accuracy: 0.8449\n",
            "Epoch 34/71\n",
            "14/14 [==============================] - 11s 784ms/step - loss: 0.3270 - accuracy: 0.8681\n",
            "Epoch 35/71\n",
            "14/14 [==============================] - 10s 697ms/step - loss: 0.2975 - accuracy: 0.8819\n",
            "Epoch 36/71\n",
            "14/14 [==============================] - 10s 659ms/step - loss: 0.2901 - accuracy: 0.8519\n",
            "Epoch 37/71\n",
            "14/14 [==============================] - 10s 731ms/step - loss: 0.3288 - accuracy: 0.8241\n",
            "Epoch 38/71\n",
            "14/14 [==============================] - 10s 722ms/step - loss: 0.2949 - accuracy: 0.8611\n",
            "Epoch 39/71\n",
            "14/14 [==============================] - 10s 710ms/step - loss: 0.3021 - accuracy: 0.8426\n",
            "Epoch 40/71\n",
            "14/14 [==============================] - 10s 662ms/step - loss: 0.2882 - accuracy: 0.8611\n",
            "Epoch 41/71\n",
            "14/14 [==============================] - 10s 715ms/step - loss: 0.2699 - accuracy: 0.8773\n",
            "Epoch 42/71\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 0.2462 - accuracy: 0.8704\n",
            "Epoch 43/71\n",
            "14/14 [==============================] - 10s 708ms/step - loss: 0.2728 - accuracy: 0.8611\n",
            "Epoch 44/71\n",
            "14/14 [==============================] - 10s 649ms/step - loss: 0.2690 - accuracy: 0.8657\n",
            "Epoch 45/71\n",
            "14/14 [==============================] - 11s 756ms/step - loss: 0.3162 - accuracy: 0.8472\n",
            "Epoch 46/71\n",
            "14/14 [==============================] - 11s 751ms/step - loss: 0.2203 - accuracy: 0.8912\n",
            "Epoch 47/71\n",
            "14/14 [==============================] - 10s 730ms/step - loss: 0.3297 - accuracy: 0.8681\n",
            "Epoch 48/71\n",
            "14/14 [==============================] - 9s 660ms/step - loss: 0.3284 - accuracy: 0.8657\n",
            "Epoch 49/71\n",
            "14/14 [==============================] - 10s 739ms/step - loss: 0.3017 - accuracy: 0.8495\n",
            "Epoch 50/71\n",
            "14/14 [==============================] - 10s 701ms/step - loss: 0.2733 - accuracy: 0.8634\n",
            "Epoch 51/71\n",
            "14/14 [==============================] - 9s 653ms/step - loss: 0.2216 - accuracy: 0.9074\n",
            "Epoch 52/71\n",
            "14/14 [==============================] - 10s 643ms/step - loss: 0.2601 - accuracy: 0.8750\n",
            "Epoch 53/71\n",
            "14/14 [==============================] - 10s 724ms/step - loss: 0.2637 - accuracy: 0.8935\n",
            "Epoch 54/71\n",
            "14/14 [==============================] - 10s 725ms/step - loss: 0.2331 - accuracy: 0.8889\n",
            "Epoch 55/71\n",
            "14/14 [==============================] - 9s 625ms/step - loss: 0.2325 - accuracy: 0.8958\n",
            "Epoch 56/71\n",
            "14/14 [==============================] - 10s 712ms/step - loss: 0.2419 - accuracy: 0.8935\n",
            "Epoch 57/71\n",
            "14/14 [==============================] - 10s 742ms/step - loss: 0.2650 - accuracy: 0.8727\n",
            "Epoch 58/71\n",
            "14/14 [==============================] - 10s 700ms/step - loss: 0.2843 - accuracy: 0.8519\n",
            "Epoch 59/71\n",
            "14/14 [==============================] - 10s 672ms/step - loss: 0.2738 - accuracy: 0.8796\n",
            "Epoch 60/71\n",
            "14/14 [==============================] - 10s 703ms/step - loss: 0.3182 - accuracy: 0.8449\n",
            "Epoch 61/71\n",
            "14/14 [==============================] - 10s 736ms/step - loss: 0.2676 - accuracy: 0.8773\n",
            "Epoch 62/71\n",
            "14/14 [==============================] - 10s 706ms/step - loss: 0.2326 - accuracy: 0.8935\n",
            "Epoch 63/71\n",
            "14/14 [==============================] - 9s 634ms/step - loss: 0.2421 - accuracy: 0.8819\n",
            "Epoch 64/71\n",
            "14/14 [==============================] - 10s 713ms/step - loss: 0.2291 - accuracy: 0.8819\n",
            "Epoch 65/71\n",
            "14/14 [==============================] - 11s 798ms/step - loss: 0.1917 - accuracy: 0.9120\n",
            "Epoch 66/71\n",
            "14/14 [==============================] - 10s 691ms/step - loss: 0.1993 - accuracy: 0.8981\n",
            "Epoch 67/71\n",
            "14/14 [==============================] - 9s 629ms/step - loss: 0.1890 - accuracy: 0.9005\n",
            "Epoch 68/71\n",
            "14/14 [==============================] - 10s 710ms/step - loss: 0.2104 - accuracy: 0.9005\n",
            "Epoch 69/71\n",
            "14/14 [==============================] - 10s 727ms/step - loss: 0.1979 - accuracy: 0.9144\n",
            "Epoch 70/71\n",
            "14/14 [==============================] - 9s 654ms/step - loss: 0.2589 - accuracy: 0.8704\n",
            "Epoch 71/71\n",
            "14/14 [==============================] - 9s 622ms/step - loss: 0.2240 - accuracy: 0.8981\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb3029c78e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('plate_classifaction_resnet.h5')"
      ],
      "metadata": {
        "id": "veKaHysQ6ZPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def classifier(path,model,shape)-> int:\n",
        "    img=cv2.imread(path)\n",
        "    img=cv2.resize(img,dsize=shape)\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    # img=preprocess_input(img_rgb)\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "    pred=model.predict(img,verbose=0)\n",
        "    idx=np.argmax(pred)\n",
        "    print('model output: ',pred)\n",
        "\n",
        "    # values={k:i for i,k in train_batches.class_indices.items()}\n",
        "    # print(values[idx])\n",
        "    return idx,pred"
      ],
      "metadata": {
        "id": "xuX71r0ot4OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x='/content/0001_license_plate_1.png'\n",
        "i,p=classifier(x,model,(224,224))\n",
        "print(classes[i],i)\n",
        "print(list(p[0]))\n",
        "plt.imshow(x)"
      ],
      "metadata": {
        "id": "NOKvh3QXSy7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classes\n",
        "train_generator[0]/255."
      ],
      "metadata": {
        "id": "x99qVhbVATR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}